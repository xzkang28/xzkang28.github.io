<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> python爬虫实践 · Hexo</title><meta name="description" content="python爬虫实践"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Hexo"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="https://github.com/xzkang28/xzkang28.github.io" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">python爬虫实践</h1><div class="post-info">Dec 24, 2016</div><div class="post-content"><a id="more"></a>
<p>之前有看到很多数据分析报告都是利用爬虫来获得原始数据，自己也想实践一下，理清楚爬虫的工作原理，本实例来源于慕课网<a href="http://www.imooc.com/learn/563" target="_blank" rel="external"> http://www.imooc.com/learn/563</a>，实例实现的目标是抓取百度百科1000个页面的数据。</p>
<p>一个基本的爬虫程序包括调度器、URL管理器、下载器和解析器，下图是爬虫的运行流程，从调度器开始调用URL管理器来获取待爬取的URL，再通过下载器把URL的内容下载到本地，最后通过解析器把内容解析成需要的数据并且再返回新的需要爬取的URL；其中调度器相当于是一个命令发布枢纽和中转站，由它来指挥三大模块（URL管理器、下载器、解析器）工作，并最终将价值数据输送给应用端。</p>
<p><img src="http://om2zpy4xm.bkt.clouddn.com/blog/20170404/175904616.png" alt="mark"></p>
<p>URL管理器的核心就是管理待抓取和已抓取的URL集合</p>
<ol>
<li>管理待抓取URL集合：先判断该URL是否已在容器内，是，不添加；不是，添加。</li>
<li>管理已抓取URL集合：分三部分：判断是否还有待爬取的URL—获取待爬取URL—爬取后，将URL从待爬取移动到已爬取</li>
</ol>
<p><img src="http://om2zpy4xm.bkt.clouddn.com/blog/20170404/175919265.png" alt="mark"></p>
<p>网页解析器，解析出目标网页中的内容，若有新url再回传给url管理器，BeatifulSoup就是使用DOM树解析网页</p>
<p><img src="http://om2zpy4xm.bkt.clouddn.com/blog/20170404/175928841.png" alt="mark"></p>
<p><img src="http://om2zpy4xm.bkt.clouddn.com/blog/20170404/175939224.png" alt="mark"></p>
<p>网页下载器：将URL指定的网页下载下来存储成一个字符串，传送给网页解析器；python里网页下载器有 urllib2 和 第三方包requests</p>
<p><img src="http://om2zpy4xm.bkt.clouddn.com/blog/20170404/175946688.png" alt="mark"></p>
<p>接下来贴代码</p>
<p> 调度器 spider_main.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> url_manager,html_downloader,html_parser,html_outputer</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderMain</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="string">"""docstring for ClassName"""</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">		self.urls = url_manager.UrlManager()</div><div class="line">		self.downloader = html_downloader.HtmlDownloader()</div><div class="line">		self.parser = html_parser.HtmlParser()</div><div class="line">		self.outputer = html_outputer.HtmlOutputer()</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">craw</span><span class="params">(self, root_url)</span>:</span></div><div class="line">		count = <span class="number">1</span></div><div class="line">		self.urls.add_new_url(root_url)</div><div class="line">		<span class="keyword">while</span> self.urls.has_new_url():</div><div class="line">			<span class="keyword">try</span>:</div><div class="line">				new_url = self.urls.get_new_url()</div><div class="line">				<span class="keyword">print</span> (<span class="string">'craw %d : %s '</span> % (count, new_url))</div><div class="line">				html_cont = self.downloader.download(new_url)</div><div class="line">				new_urls,new_data = self.parser.parser(new_url,html_cont)</div><div class="line">				self.urls.add_new_urls(new_urls)</div><div class="line">				self.outputer.collect_data(new_data)</div><div class="line"></div><div class="line">				<span class="keyword">if</span> count == <span class="number">10</span>:</div><div class="line">					print(<span class="string">'10'</span>)</div><div class="line">					<span class="keyword">break</span></div><div class="line"></div><div class="line">				count = count + <span class="number">1</span></div><div class="line">			<span class="keyword">except</span> :</div><div class="line">				<span class="keyword">print</span> (<span class="string">'craw failed'</span>)</div><div class="line">			</div><div class="line"></div><div class="line">		self.outputer.output_html()</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	root_url = <span class="string">"http://baike.baidu.com/view/21087.htm"</span></div><div class="line">	obj_spider = SpiderMain()</div><div class="line">	obj_spider.craw(root_url)</div></pre></td></tr></table></figure>
<p> url管理器 url_manager.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UrlManager</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="string">"""docstring for UrlManager"""</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">		self.new_urls = set()</div><div class="line">		self.old_urls = set()</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">add_new_url</span><span class="params">(self, url)</span>:</span></div><div class="line">		<span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">			<span class="keyword">return</span></div><div class="line">		<span class="keyword">if</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.new_urls <span class="keyword">and</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.old_urls:</div><div class="line">			self.new_urls.add(url)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">add_new_urls</span><span class="params">(self, urls)</span>:</span></div><div class="line">		<span class="keyword">if</span> urls <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> len(urls) == <span class="number">0</span>:</div><div class="line">			<span class="keyword">return</span></div><div class="line">		<span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">			self.add_new_url(url)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">has_new_url</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="keyword">return</span> len(self.new_urls) != <span class="number">0</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">get_new_url</span><span class="params">(self)</span>:</span></div><div class="line">		new_url = self.new_urls.pop()</div><div class="line">		self.old_urls.add(new_url)</div><div class="line">		<span class="keyword">return</span> new_url</div></pre></td></tr></table></figure>
<p> 网页下载器 html_downloader.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlDownloader</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="string">"""docstring for HtmlDownloader"""</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self,url)</span>:</span></div><div class="line">		<span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">			<span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"></div><div class="line">		response = urllib.request.urlopen(url)</div><div class="line">		<span class="keyword">if</span> response.getcode() != <span class="number">200</span>:</div><div class="line">			<span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"></div><div class="line">		<span class="keyword">return</span> response.read()</div></pre></td></tr></table></figure>
<p> 网页解析器 html_parser.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> urllib.parse</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlParser</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="string">"""docstring for HtmlParser"""</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(self, page_url, html_cont)</span>:</span></div><div class="line">		<span class="keyword">if</span> page_url <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> html_cont <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">			<span class="keyword">return</span></div><div class="line"></div><div class="line">		soup = BeautifulSoup(html_cont,<span class="string">'html.parser'</span>,from_encoding=<span class="string">'utf-8'</span>)</div><div class="line">		new_urls = self._get_new_urls(page_url, soup)</div><div class="line">		new_data = self._get_new_data(page_url, soup)</div><div class="line">		<span class="keyword">return</span> new_urls,new_data</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">_get_new_urls</span><span class="params">(self, page_url, soup)</span>:</span></div><div class="line">		new_urls = set()</div><div class="line">		links = soup.find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">r"/view/\d+\.htm"</span>))</div><div class="line">		<span class="keyword">for</span> link <span class="keyword">in</span> links:</div><div class="line">			new_url = link[<span class="string">'href'</span>]</div><div class="line">			new_full_url = urllib.parse.urljoin(page_url, new_url)</div><div class="line">			new_urls.add(new_full_url)</div><div class="line">		<span class="keyword">return</span> new_urls</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">_get_new_data</span><span class="params">(self, page_url, soup)</span>:</span></div><div class="line">		res_data = &#123;&#125;</div><div class="line"></div><div class="line">		res_data[<span class="string">'url'</span>] = page_url</div><div class="line"></div><div class="line">		title_node = soup.find(<span class="string">'dd'</span>, class_=<span class="string">"lemmaWgt-lemmaTitle-title"</span>).find(<span class="string">"h1"</span>)</div><div class="line">		res_data[<span class="string">'title'</span>] = title_node.get_text()</div><div class="line"></div><div class="line">		summary_node = soup.find(<span class="string">'div'</span>, class_=<span class="string">"lemma-summary"</span>)</div><div class="line">		res_data[<span class="string">'summary'</span>] = summary_node.get_text()</div><div class="line"></div><div class="line">		<span class="keyword">return</span> res_data</div></pre></td></tr></table></figure>
<p> 数据输出 html_outputer.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlOutputer</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="string">"""docstring for HtmlOutputer"""</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">		self.datas = []</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">collect_data</span><span class="params">(self,data)</span>:</span></div><div class="line">		<span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">			<span class="keyword">return</span></div><div class="line">		self.datas.append(data)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">output_html</span><span class="params">(self)</span>:</span></div><div class="line">		fout = open(<span class="string">'output.html'</span>, <span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>)</div><div class="line"></div><div class="line"></div><div class="line">		fout.write(<span class="string">"&lt;html&gt;"</span>)</div><div class="line"></div><div class="line">		fout.write(<span class="string">"&lt;meta charset=\'utf-8\'&gt;"</span>)</div><div class="line">		fout.write(<span class="string">"&lt;body&gt;"</span>)</div><div class="line">		fout.write(<span class="string">"&lt;table&gt;"</span>)</div><div class="line"></div><div class="line">		<span class="keyword">for</span> data <span class="keyword">in</span> self.datas:</div><div class="line">			fout.write(<span class="string">"&lt;tr&gt;"</span>)</div><div class="line">			fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'url'</span>])</div><div class="line">			fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'title'</span>])</div><div class="line">			fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'summary'</span>])</div><div class="line">			fout.write(<span class="string">"&lt;/tr&gt;"</span>)</div><div class="line"></div><div class="line">		fout.write(<span class="string">"&lt;/table&gt;"</span>)</div><div class="line">		fout.write(<span class="string">"&lt;/body&gt;"</span>)</div><div class="line">		fout.write(<span class="string">"&lt;/html&gt;"</span>)</div><div class="line">		</div><div class="line">		fout.close()</div></pre></td></tr></table></figure></div></article></div></main><footer><div class="paginator"><a href="/2017/01/05/20170105-游戏背后的数据分析/" class="prev">PREV</a><a href="/2016/11/26/20161126-如何建立用户画像/" class="next">NEXT</a></div><div class="copyright"><p>© 2017 <a href="http://yoursite.com">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-96130216-2",'auto');ga('send','pageview');</script></body></html>